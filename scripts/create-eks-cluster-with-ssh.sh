#!/bin/bash

# SSH ì ‘ê·¼ ì˜µì…˜ì´ ìˆëŠ” EKS í´ëŸ¬ìŠ¤í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸

set -e

# ê³µí†µ í•¨ìˆ˜ ë¡œë“œ
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )"
source "$SCRIPT_DIR/common-functions.sh"

# í•„ìˆ˜ ë„êµ¬ í™•ì¸
check_required_tools "eksctl" "aws"

# AWS í™˜ê²½ í™•ì¸ (ì•„ì§ í™•ì¸ë˜ì§€ ì•Šì€ ê²½ìš°)
if [ -z "$AWS_ACCOUNT_ID" ]; then
    check_aws_environment
fi

# ì„¤ì • ë³€ìˆ˜
CLUSTER_NAME=${CLUSTER_NAME:-datadog-runner-cluster}
NODE_GROUP_NAME="$CLUSTER_NAME-nodes"
NODE_TYPE=${NODE_TYPE:-t3.medium}
MIN_NODES=${MIN_NODES:-1}
MAX_NODES=${MAX_NODES:-3}
DESIRED_NODES=${DESIRED_NODES:-2}
SSH_KEY_NAME=${SSH_KEY_NAME:-tam-sandbox-key}

log_info "ğŸ¯ EKS í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹œì‘ (SSH ì ‘ê·¼ í¬í•¨)"
echo "   í´ëŸ¬ìŠ¤í„°ëª…: $CLUSTER_NAME"
echo "   ì§€ì—­: $AWS_REGION"
echo "   ê³„ì •: $AWS_ACCOUNT_ID"
echo "   ë…¸ë“œ íƒ€ì…: $NODE_TYPE"
echo "   ë…¸ë“œ ìˆ˜: $MIN_NODES-$MAX_NODES (ëª©í‘œ: $DESIRED_NODES)"
echo "   SSH í‚¤: $SSH_KEY_NAME"
echo ""

# í´ëŸ¬ìŠ¤í„° ì¶©ëŒ í™•ì¸
if ! check_cluster_conflict "$CLUSTER_NAME" "$AWS_REGION"; then
    log_info "ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
    exit 0
fi

# AWSì—ì„œ í‚¤ í˜ì–´ ì¡´ì¬ í™•ì¸
log_info "AWS EC2 í‚¤ í˜ì–´ í™•ì¸ ì¤‘..."
if ! aws ec2 describe-key-pairs --key-names "$SSH_KEY_NAME" --region "$AWS_REGION" &> /dev/null; then
    log_warning "AWS EC2ì— '$SSH_KEY_NAME' í‚¤ í˜ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    echo ""
    echo "ë‹¤ìŒ ë°©ë²• ì¤‘ ì„ íƒí•˜ì„¸ìš”:"
    echo "1. ê¸°ì¡´ .pem í‚¤ë¥¼ AWSì— ë“±ë¡"
    echo "2. SSH ì—†ì´ í´ëŸ¬ìŠ¤í„° ìƒì„± (./scripts/create-eks-cluster.sh ì‚¬ìš©)"
    echo ""
    
    read -p "ğŸ¤” ê¸°ì¡´ .pem í‚¤ë¥¼ AWSì— ë“±ë¡í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        # SSH í‚¤ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        if [ ! -f "./scripts/setup-ssh-key.sh" ]; then
            log_error "setup-ssh-key.sh ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            exit 1
        fi
        
        ./scripts/setup-ssh-key.sh
        
        # public keyë¥¼ AWSì— ë“±ë¡
        log_info "ğŸ“¤ AWS EC2ì— í‚¤ í˜ì–´ ë“±ë¡ ì¤‘..."
        aws ec2 import-key-pair \
            --key-name "$SSH_KEY_NAME" \
            --public-key-material fileb://~/.ssh/id_rsa.pub \
            --region "$AWS_REGION"
        
        log_success "AWS EC2ì— í‚¤ í˜ì–´ ë“±ë¡ ì™„ë£Œ!"
    else
        log_info "SSH ì—†ì´ í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•˜ë ¤ë©´ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:"
        echo "  ./scripts/create-eks-cluster.sh"
        exit 0
    fi
fi

# EKS í´ëŸ¬ìŠ¤í„° ìƒì„± (SSH ì ‘ê·¼ í¬í•¨)
log_info "ğŸ—ï¸  EKS í´ëŸ¬ìŠ¤í„° ìƒì„± ì¤‘... (ì•½ 15-20ë¶„ ì†Œìš”)"
eksctl create cluster \
    --name=$CLUSTER_NAME \
    --region=$AWS_REGION \
    --version=1.28 \
    --nodegroup-name=$NODE_GROUP_NAME \
    --node-type=$NODE_TYPE \
    --nodes-min=$MIN_NODES \
    --nodes-max=$MAX_NODES \
    --nodes=$DESIRED_NODES \
    --with-oidc \
    --ssh-access \
    --ssh-public-key=$SSH_KEY_NAME \
    --managed

# AWS Load Balancer Controller ì„¤ì¹˜
log_info "ğŸ”§ AWS Load Balancer Controller ì„¤ì¹˜ ì¤‘..."

# OIDC ê³µê¸‰ì ì—°ê²°
eksctl utils associate-iam-oidc-provider --region=$AWS_REGION --cluster=$CLUSTER_NAME --approve

# IAM ì—­í•  ìƒì„±
eksctl create iamserviceaccount \
    --cluster=$CLUSTER_NAME \
    --namespace=kube-system \
    --name=aws-load-balancer-controller \
    --role-name="AmazonEKSLoadBalancerControllerRole" \
    --attach-policy-arn=arn:aws:iam::aws:policy/ElasticLoadBalancingFullAccess \
    --approve \
    --region=$AWS_REGION

# Helmì„ í†µí•´ AWS Load Balancer Controller ì„¤ì¹˜
helm repo add eks https://aws.github.io/eks-charts
helm repo update

kubectl apply -k "github.com/aws/eks-charts/stable/aws-load-balancer-controller//crds?ref=master"

helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
    -n kube-system \
    --set clusterName=$CLUSTER_NAME \
    --set serviceAccount.create=false \
    --set serviceAccount.name=aws-load-balancer-controller \
    --set region=$AWS_REGION \
    --set vpcId=$(aws eks describe-cluster --name $CLUSTER_NAME --query "cluster.resourcesVpcConfig.vpcId" --output text --region $AWS_REGION)

log_success "EKS í´ëŸ¬ìŠ¤í„° ìƒì„± ì™„ë£Œ! (SSH ì ‘ê·¼ ê°€ëŠ¥)"
echo ""
log_info "SSH ì ‘ê·¼ ë°©ë²•:"
echo "  # ë…¸ë“œ ì •ë³´ í™•ì¸"
echo "  kubectl get nodes -o wide"
echo "  "
echo "  # SSH ì ‘ê·¼ ì˜ˆì‹œ"
echo "  ssh -i ~/.ssh/id_rsa ec2-user@<NODE_IP>"
echo ""
log_info "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì—°ê²° í™•ì¸:"
echo "  kubectl get nodes"
echo "  kubectl get pods -A"
